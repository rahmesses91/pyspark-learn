{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python String Methods for Data Engineering\n",
    "\n",
    "This notebook covers essential string methods used in Data Engineering for:\n",
    "- Data cleaning and normalization\n",
    "- Parsing log files, CSV data, and structured text\n",
    "- Validating and transforming data fields\n",
    "\n",
    "**Categories covered:**\n",
    "1. Cleaning & Normalization\n",
    "2. Case Transformation\n",
    "3. Splitting & Joining\n",
    "4. Search & Find\n",
    "5. Validation & Checking\n",
    "6. Formatting & Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: Cleaning & Normalization\n",
    "\n",
    "The most common task in Data Engineering - cleaning messy data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 `strip()` - Remove Whitespace from Both Ends\n",
    "\n",
    "**What it does:** Removes leading and trailing whitespace (or specified characters)\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.strip([chars])\n",
    "       ↓        ↓\n",
    "       |        └── Optional: specific characters to remove\n",
    "       └── The string to clean\n",
    "```\n",
    "\n",
    "**DE Use Case:** Raw data from CSV files, databases, or APIs often has extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample: Raw customer data from a CSV file\n",
    "raw_records = [\n",
    "    \"   John Doe   \",\n",
    "    \"Jane Smith  \",\n",
    "    \"  Bob Johnson\",\n",
    "    \"Alice Brown\"\n",
    "]\n",
    "\n",
    "print(\"Before strip():\")\n",
    "print(\"-\" * 30)\n",
    "for record in raw_records:\n",
    "    print(f\"'{record}'  (length: {len(record)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply strip() to clean the data\n",
    "cleaned_records = [record.strip() for record in raw_records]\n",
    "\n",
    "print(\"After strip():\")\n",
    "print(\"-\" * 30)\n",
    "for record in cleaned_records:\n",
    "    print(f\"'{record}'  (length: {len(record)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip() with specific characters\n",
    "# Common in DE: removing delimiters, quotes, or special chars\n",
    "\n",
    "raw_ids = [\n",
    "    \"###ID_001###\",\n",
    "    \"---ID_002---\",\n",
    "    \"***ID_003***\"\n",
    "]\n",
    "\n",
    "print(\"Removing specific characters:\")\n",
    "print(\"-\" * 40)\n",
    "for raw_id in raw_ids:\n",
    "    # strip() removes ANY of the characters in the string, not the whole string\n",
    "    cleaned = raw_id.strip(\"#-*\")\n",
    "    print(f\"'{raw_id}' → '{cleaned}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 `lstrip()` and `rstrip()` - Remove from One Side Only\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.lstrip([chars])  # Left side only\n",
    "string.rstrip([chars])  # Right side only\n",
    "```\n",
    "\n",
    "**DE Use Cases:**\n",
    "- `lstrip('0')`: Remove leading zeros from IDs\n",
    "- `rstrip('\\n')`: Remove trailing newlines from file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstrip() - Remove leading zeros from IDs\n",
    "# Common scenario: ID fields stored with padding\n",
    "\n",
    "padded_ids = [\"000042\", \"000001\", \"001234\", \"000000\"]\n",
    "\n",
    "print(\"Removing leading zeros:\")\n",
    "print(\"-\" * 30)\n",
    "for pid in padded_ids:\n",
    "    cleaned = pid.lstrip('0')\n",
    "    # Handle edge case: if all zeros, keep at least one\n",
    "    cleaned = cleaned if cleaned else '0'\n",
    "    print(f\"'{pid}' → '{cleaned}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rstrip() - Remove trailing newlines from file data\n",
    "# Common when reading lines from files\n",
    "\n",
    "file_lines = [\n",
    "    \"data_value_1\\n\",\n",
    "    \"data_value_2\\n\\n\",\n",
    "    \"data_value_3\\r\\n\"\n",
    "]\n",
    "\n",
    "print(\"Removing trailing newlines:\")\n",
    "print(\"-\" * 40)\n",
    "for line in file_lines:\n",
    "    cleaned = line.rstrip('\\n\\r')\n",
    "    print(f\"{repr(line):25} → '{cleaned}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 `replace()` - Replace Substrings\n",
    "\n",
    "**What it does:** Replaces all (or limited) occurrences of a substring\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.replace(old, new[, count])\n",
    "               ↓    ↓      ↓\n",
    "               |    |      └── Optional: max replacements\n",
    "               |    └── What to replace with\n",
    "               └── What to find and replace\n",
    "```\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Standardizing phone numbers, dates\n",
    "- Fixing inconsistent delimiters\n",
    "- Data masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE Use Case: Standardizing phone numbers\n",
    "# Different sources have different formats\n",
    "\n",
    "raw_phones = [\n",
    "    \"123-456-7890\",\n",
    "    \"(123) 456-7890\",\n",
    "    \"123.456.7890\",\n",
    "    \"123 456 7890\"\n",
    "]\n",
    "\n",
    "print(\"Standardizing phone numbers to digits only:\")\n",
    "print(\"-\" * 40)\n",
    "for phone in raw_phones:\n",
    "    # Chain multiple replace() calls\n",
    "    cleaned = phone.replace(\"-\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "    print(f\"'{phone:20}' → '{cleaned}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace() with count parameter\n",
    "# Useful when you only want to replace first N occurrences\n",
    "\n",
    "log_line = \"ERROR: Connection ERROR in module ERROR_HANDLER\"\n",
    "\n",
    "print(f\"Original: {log_line}\")\n",
    "print(f\"Replace all:    {log_line.replace('ERROR', 'WARN')}\")\n",
    "print(f\"Replace first:  {log_line.replace('ERROR', 'WARN', 1)}\")\n",
    "print(f\"Replace first 2: {log_line.replace('ERROR', 'WARN', 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 `removeprefix()` and `removesuffix()` (Python 3.9+)\n",
    "\n",
    "**What they do:** Remove a specific prefix or suffix if present\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.removeprefix(prefix)  # Remove from start\n",
    "string.removesuffix(suffix)  # Remove from end\n",
    "```\n",
    "\n",
    "**Important:** Unlike `strip()`, these remove the EXACT string, not individual characters\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Removing consistent prefixes from IDs (ORDER_, TXN_, etc.)\n",
    "- Removing file extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removeprefix() - Clean prefixes from IDs\n",
    "order_ids = [\n",
    "    \"ORD_12345\",\n",
    "    \"ORD_67890\",\n",
    "    \"TXN_11111\",  # Different prefix - won't be affected\n",
    "    \"ORD_99999\"\n",
    "]\n",
    "\n",
    "print(\"Removing 'ORD_' prefix:\")\n",
    "print(\"-\" * 30)\n",
    "for oid in order_ids:\n",
    "    cleaned = oid.removeprefix(\"ORD_\")\n",
    "    print(f\"'{oid}' → '{cleaned}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removesuffix() - Remove file extensions\n",
    "filenames = [\n",
    "    \"report_2024.csv\",\n",
    "    \"data_export.csv\",\n",
    "    \"summary.json\",  # Different extension - won't be affected\n",
    "    \"transactions.csv\"\n",
    "]\n",
    "\n",
    "print(\"Removing '.csv' suffix:\")\n",
    "print(\"-\" * 30)\n",
    "for fname in filenames:\n",
    "    cleaned = fname.removesuffix(\".csv\")\n",
    "    print(f\"'{fname}' → '{cleaned}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### strip() vs removeprefix()/removesuffix() - Key Difference!\n",
    "\n",
    "This is a common source of confusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Understanding the difference\n",
    "\n",
    "text = \"aaahelloaaa\"\n",
    "\n",
    "# strip('aaa') removes individual 'a' characters from both ends\n",
    "# NOT the string 'aaa' as a unit\n",
    "print(f\"strip('aaa'):        '{text}' → '{text.strip('aaa')}'\")\n",
    "\n",
    "# removeprefix/removesuffix removes the EXACT string\n",
    "print(f\"removeprefix('aaa'): '{text}' → '{text.removeprefix('aaa')}'\")\n",
    "print(f\"removesuffix('aaa'): '{text}' → '{text.removesuffix('aaa')}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"strip() = remove any of these CHARACTERS\")\n",
    "print(\"removeprefix() = remove this exact STRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Case Transformation\n",
    "\n",
    "Essential for data normalization and standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 `lower()` and `upper()` - Case Conversion\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.lower()  # Convert all to lowercase\n",
    "string.upper()  # Convert all to uppercase\n",
    "```\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Normalizing emails (always lowercase)\n",
    "- Case-insensitive comparisons\n",
    "- Standardizing codes/identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE Use Case: Normalizing email addresses\n",
    "# Emails should always be stored in lowercase for consistency\n",
    "\n",
    "raw_emails = [\n",
    "    \"John.Doe@Company.COM\",\n",
    "    \"JANE.SMITH@EXAMPLE.ORG\",\n",
    "    \"Bob_Jones@Test.Net\",\n",
    "    \"alice@domain.com\"\n",
    "]\n",
    "\n",
    "print(\"Normalizing emails to lowercase:\")\n",
    "print(\"-\" * 50)\n",
    "for email in raw_emails:\n",
    "    normalized = email.lower()\n",
    "    print(f\"{email:30} → {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE Use Case: Standardizing country codes\n",
    "# Codes should be uppercase for consistency\n",
    "\n",
    "country_codes = [\"us\", \"Gb\", \"DE\", \"fr\", \"JP\"]\n",
    "\n",
    "print(\"Standardizing country codes to uppercase:\")\n",
    "print(\"-\" * 30)\n",
    "for code in country_codes:\n",
    "    standardized = code.upper()\n",
    "    print(f\"'{code}' → '{standardized}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE Use Case: Case-insensitive comparison\n",
    "# When matching records from different sources\n",
    "\n",
    "source_a = \"John Doe\"\n",
    "source_b = \"JOHN DOE\"\n",
    "\n",
    "# Direct comparison fails\n",
    "print(f\"Direct comparison: '{source_a}' == '{source_b}' → {source_a == source_b}\")\n",
    "\n",
    "# Normalize before comparing\n",
    "print(f\"Normalized:        '{source_a.lower()}' == '{source_b.lower()}' → {source_a.lower() == source_b.lower()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 `title()` and `capitalize()` - Proper Formatting\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.title()       # Capitalize First Letter Of Each Word\n",
    "string.capitalize()  # Capitalize only first letter of string\n",
    "```\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Formatting names for display\n",
    "- Standardizing city/country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting customer names\n",
    "raw_names = [\n",
    "    \"john doe\",\n",
    "    \"JANE SMITH\",\n",
    "    \"bOB jOHNSON\",\n",
    "    \"alice brown\"\n",
    "]\n",
    "\n",
    "print(\"Formatting names with title():\")\n",
    "print(\"-\" * 30)\n",
    "for name in raw_names:\n",
    "    formatted = name.title()\n",
    "    print(f\"'{name:15}' → '{formatted}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title() vs capitalize()\n",
    "text = \"hello world from python\"\n",
    "\n",
    "print(f\"Original:    '{text}'\")\n",
    "print(f\"title():     '{text.title()}'\")\n",
    "print(f\"capitalize(): '{text.capitalize()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: Splitting & Joining\n",
    "\n",
    "Critical for parsing structured data (CSV, logs, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 `split()` - Break String into List\n",
    "\n",
    "**What it does:** Splits a string into a list using a delimiter\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.split([sep[, maxsplit]])\n",
    "              ↓       ↓\n",
    "              |       └── Optional: max number of splits\n",
    "              └── Delimiter (default: whitespace)\n",
    "```\n",
    "\n",
    "**Returns:** A list of substrings\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Parsing CSV rows\n",
    "- Extracting fields from log lines\n",
    "- Breaking apart paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic split() - parsing CSV-like data\n",
    "csv_row = \"John,Doe,30,Engineer,New York\"\n",
    "\n",
    "# Split on comma\n",
    "fields = csv_row.split(\",\")\n",
    "\n",
    "print(f\"Original: '{csv_row}'\")\n",
    "print(f\"Split:    {fields}\")\n",
    "print(f\"Type:     {type(fields)}\")\n",
    "print()\n",
    "print(\"Accessing individual fields:\")\n",
    "print(f\"  fields[0] (first name): {fields[0]}\")\n",
    "print(f\"  fields[1] (last name):  {fields[1]}\")\n",
    "print(f\"  fields[2] (age):        {fields[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split() with maxsplit - Parsing log lines\n",
    "# Common pattern: split date/time, then keep message together\n",
    "\n",
    "log_line = \"2024-01-15 10:30:45 ERROR Connection failed: timeout after 30s\"\n",
    "\n",
    "# Without maxsplit - splits everything\n",
    "all_parts = log_line.split(\" \")\n",
    "print(f\"split(' '):     {all_parts}\")\n",
    "print(f\"  → {len(all_parts)} parts (message is fragmented!)\")\n",
    "print()\n",
    "\n",
    "# With maxsplit=3 - keeps message together\n",
    "parts = log_line.split(\" \", 3)\n",
    "print(f\"split(' ', 3):  {parts}\")\n",
    "print(f\"  → Date: {parts[0]}\")\n",
    "print(f\"  → Time: {parts[1]}\")\n",
    "print(f\"  → Level: {parts[2]}\")\n",
    "print(f\"  → Message: {parts[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split() with no argument - splits on whitespace\n",
    "# Handles multiple spaces, tabs, newlines automatically\n",
    "\n",
    "messy_data = \"John    Doe\\t\\t30   Engineer\"\n",
    "\n",
    "print(f\"Original: {repr(messy_data)}\")\n",
    "print(f\"split():  {messy_data.split()}\")\n",
    "print()\n",
    "print(\"Note: split() with no args handles multiple whitespace cleanly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 `rsplit()` - Split from Right Side\n",
    "\n",
    "**Syntax:** Same as `split()`, but splits from the right\n",
    "\n",
    "**DE Use Case:** When you want the LAST N parts (e.g., file path → filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsplit() - Extract filename from path\n",
    "file_path = \"/home/user/data/projects/report_2024.csv\"\n",
    "\n",
    "# Get just the filename (last part)\n",
    "parts = file_path.rsplit(\"/\", 1)\n",
    "print(f\"Path: {file_path}\")\n",
    "print(f\"rsplit('/', 1): {parts}\")\n",
    "print(f\"  → Directory: {parts[0]}\")\n",
    "print(f\"  → Filename:  {parts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split() vs rsplit() comparison\n",
    "text = \"a.b.c.d.e\"\n",
    "\n",
    "print(f\"Original: {text}\")\n",
    "print(f\"split('.', 2):  {text.split('.', 2)}   ← splits from LEFT\")\n",
    "print(f\"rsplit('.', 2): {text.rsplit('.', 2)}  ← splits from RIGHT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 `join()` - Combine List into String\n",
    "\n",
    "**What it does:** The opposite of `split()` - joins list elements with a separator\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "separator.join(iterable)\n",
    "    ↓            ↓\n",
    "    |            └── List/tuple of strings to join\n",
    "    └── String to put between elements\n",
    "```\n",
    "\n",
    "**Note:** The separator calls `.join()`, not the list!\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Building CSV rows\n",
    "- Creating file paths\n",
    "- Constructing queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join() - Building CSV rows\n",
    "fields = [\"John\", \"Doe\", \"30\", \"Engineer\"]\n",
    "\n",
    "# Join with comma\n",
    "csv_row = \",\".join(fields)\n",
    "\n",
    "print(f\"List:    {fields}\")\n",
    "print(f\"Joined:  '{csv_row}'\")\n",
    "print()\n",
    "\n",
    "# Join with different separators\n",
    "print(f\"Tab-separated:   '{chr(9).join(fields)}'\")\n",
    "print(f\"Pipe-separated:  '{'|'.join(fields)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join() - Building file paths\n",
    "path_parts = [\"home\", \"user\", \"data\", \"file.csv\"]\n",
    "\n",
    "unix_path = \"/\".join(path_parts)\n",
    "windows_path = \"\\\\\".join(path_parts)\n",
    "\n",
    "print(f\"Parts:        {path_parts}\")\n",
    "print(f\"Unix path:    {unix_path}\")\n",
    "print(f\"Windows path: {windows_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: join() only works with strings!\n",
    "# If you have numbers, convert them first\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# This will fail:\n",
    "# \",\".join(numbers)  # TypeError!\n",
    "\n",
    "# Convert to strings first\n",
    "number_strings = [str(n) for n in numbers]\n",
    "result = \",\".join(number_strings)\n",
    "\n",
    "print(f\"Numbers: {numbers}\")\n",
    "print(f\"Joined:  '{result}'\")\n",
    "print()\n",
    "\n",
    "# One-liner version:\n",
    "result_oneliner = \",\".join(str(n) for n in numbers)\n",
    "print(f\"One-liner: '{result_oneliner}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 `partition()` - Split into Three Parts\n",
    "\n",
    "**What it does:** Splits on FIRST occurrence, returns tuple of (before, separator, after)\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.partition(sep)\n",
    "→ Returns: (before_sep, sep, after_sep)\n",
    "```\n",
    "\n",
    "**DE Use Case:** Extracting key-value pairs, splitting on first delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition() - Parsing key-value pairs\n",
    "# Common in config files, query strings\n",
    "\n",
    "config_lines = [\n",
    "    \"database_host=localhost\",\n",
    "    \"connection_string=host=db;port=5432;user=admin\",  # Value contains '='!\n",
    "    \"timeout=30\"\n",
    "]\n",
    "\n",
    "print(\"Parsing config with partition():\")\n",
    "print(\"-\" * 50)\n",
    "for line in config_lines:\n",
    "    key, sep, value = line.partition(\"=\")\n",
    "    print(f\"Key: '{key:20}' | Value: '{value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why partition() is better than split() for key-value:\n",
    "\n",
    "line = \"connection_string=host=db;port=5432\"\n",
    "\n",
    "# split() breaks on ALL '=' characters\n",
    "split_result = line.split(\"=\")\n",
    "print(f\"split('='):     {split_result}\")\n",
    "print(f\"  → Value is fragmented!\")\n",
    "print()\n",
    "\n",
    "# partition() only splits on FIRST '='\n",
    "key, _, value = line.partition(\"=\")\n",
    "print(f\"partition('='): ('{key}', '=', '{value}')\")\n",
    "print(f\"  → Value stays intact!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Search & Find\n",
    "\n",
    "Locating substrings within data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 `find()` and `rfind()` - Locate Substrings\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.find(sub[, start[, end]])   # Search from left\n",
    "string.rfind(sub[, start[, end]])  # Search from right\n",
    "```\n",
    "\n",
    "**Returns:** Index of first/last occurrence, or **-1 if not found**\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Checking if substring exists\n",
    "- Locating delimiters for parsing\n",
    "- Extracting parts of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find() - Basic usage\n",
    "log = \"ERROR: Connection failed at 10:30:45\"\n",
    "\n",
    "# Find returns index position\n",
    "error_pos = log.find(\"ERROR\")\n",
    "warning_pos = log.find(\"WARNING\")\n",
    "\n",
    "print(f\"Log: '{log}'\")\n",
    "print(f\"find('ERROR'):   {error_pos}  (found at index 0)\")\n",
    "print(f\"find('WARNING'): {warning_pos}  (-1 means not found)\")\n",
    "print()\n",
    "\n",
    "# Common pattern: check if substring exists\n",
    "if log.find(\"ERROR\") != -1:\n",
    "    print(\"This is an error log!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfind() - Find from right (last occurrence)\n",
    "path = \"/home/user/data/archive/file.csv\"\n",
    "\n",
    "# Find last slash to get filename\n",
    "last_slash = path.rfind(\"/\")\n",
    "filename = path[last_slash + 1:]\n",
    "\n",
    "print(f\"Path: {path}\")\n",
    "print(f\"Last '/' at index: {last_slash}\")\n",
    "print(f\"Filename: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find() vs 'in' operator\n",
    "text = \"Hello World\"\n",
    "\n",
    "# 'in' operator - just checks existence (True/False)\n",
    "print(f\"'World' in text: {'World' in text}\")\n",
    "\n",
    "# find() - gives you the position\n",
    "print(f\"text.find('World'): {text.find('World')}\")\n",
    "\n",
    "print(\"\\nUse 'in' when you just need True/False\")\n",
    "print(\"Use find() when you need the position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 `count()` - Count Occurrences\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.count(sub[, start[, end]])\n",
    "```\n",
    "\n",
    "**Returns:** Number of non-overlapping occurrences\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Validating data format (e.g., email has exactly one @)\n",
    "- Counting delimiters to verify field count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count() - Data validation example\n",
    "emails = [\n",
    "    \"john@company.com\",\n",
    "    \"invalid.email.com\",    # No @\n",
    "    \"bad@@email.com\",        # Two @\n",
    "    \"jane@dept@company.com\"  # Two @\n",
    "]\n",
    "\n",
    "print(\"Email validation using count():\")\n",
    "print(\"-\" * 50)\n",
    "for email in emails:\n",
    "    at_count = email.count(\"@\")\n",
    "    is_valid = at_count == 1\n",
    "    print(f\"{email:25} | @count: {at_count} | valid: {is_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count() - Verify CSV field count\n",
    "csv_rows = [\n",
    "    \"John,Doe,30,Engineer\",\n",
    "    \"Jane,Smith,25\",              # Missing field\n",
    "    \"Bob,Johnson,40,Manager,NYC\"  # Extra field\n",
    "]\n",
    "\n",
    "expected_fields = 4  # We expect 4 fields (3 commas)\n",
    "\n",
    "print(\"Validating CSV row structure:\")\n",
    "print(\"-\" * 50)\n",
    "for row in csv_rows:\n",
    "    comma_count = row.count(\",\")\n",
    "    actual_fields = comma_count + 1\n",
    "    is_valid = actual_fields == expected_fields\n",
    "    print(f\"{row:30} | fields: {actual_fields} | valid: {is_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: Validation & Checking\n",
    "\n",
    "Methods that return `True` or `False` - perfect for data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 `startswith()` and `endswith()` - Check Prefix/Suffix\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.startswith(prefix)   # Check beginning\n",
    "string.endswith(suffix)     # Check ending\n",
    "\n",
    "# Can also check multiple options with tuple:\n",
    "string.startswith((\"opt1\", \"opt2\", \"opt3\"))\n",
    "```\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Filtering files by extension\n",
    "- Identifying record types by prefix\n",
    "- Validating formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startswith() - Filtering by prefix\n",
    "transaction_ids = [\n",
    "    \"ORD_12345\",\n",
    "    \"TXN_67890\",\n",
    "    \"REF_11111\",\n",
    "    \"ORD_22222\",\n",
    "    \"TXN_33333\"\n",
    "]\n",
    "\n",
    "# Filter only orders\n",
    "orders = [tid for tid in transaction_ids if tid.startswith(\"ORD_\")]\n",
    "print(f\"All transactions: {transaction_ids}\")\n",
    "print(f\"Only orders:      {orders}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endswith() with tuple - Check multiple extensions\n",
    "files = [\n",
    "    \"report.csv\",\n",
    "    \"data.json\",\n",
    "    \"image.png\",\n",
    "    \"config.yaml\",\n",
    "    \"archive.parquet\"\n",
    "]\n",
    "\n",
    "# Filter data files (csv, json, parquet)\n",
    "data_extensions = (\".csv\", \".json\", \".parquet\")\n",
    "data_files = [f for f in files if f.endswith(data_extensions)]\n",
    "\n",
    "print(f\"All files:  {files}\")\n",
    "print(f\"Data files: {data_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 `isdigit()`, `isalpha()`, `isalnum()` - Character Type Checks\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.isdigit()  # True if all characters are digits (0-9)\n",
    "string.isalpha()  # True if all characters are letters (a-z, A-Z)\n",
    "string.isalnum()  # True if all characters are alphanumeric\n",
    "```\n",
    "\n",
    "**DE Use Cases:**\n",
    "- Validating ID fields\n",
    "- Checking numeric strings before conversion\n",
    "- Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isdigit() - Validate before converting to int\n",
    "user_inputs = [\"123\", \"45.6\", \"abc\", \"789\", \"-10\", \"100\"]\n",
    "\n",
    "print(\"Validating numeric inputs:\")\n",
    "print(\"-\" * 40)\n",
    "for inp in user_inputs:\n",
    "    is_valid = inp.isdigit()\n",
    "    print(f\"'{inp:6}' isdigit(): {is_valid}\")\n",
    "\n",
    "print(\"\\nNote: isdigit() is strict - no decimals, no negatives!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isalnum() - Validate usernames/IDs\n",
    "usernames = [\n",
    "    \"user123\",\n",
    "    \"john_doe\",     # underscore is not alphanumeric\n",
    "    \"jane.smith\",   # dot is not alphanumeric\n",
    "    \"bobJohnson\",\n",
    "    \"user@test\"     # @ is not alphanumeric\n",
    "]\n",
    "\n",
    "print(\"Validating usernames (alphanumeric only):\")\n",
    "print(\"-\" * 40)\n",
    "for username in usernames:\n",
    "    is_valid = username.isalnum()\n",
    "    print(f\"'{username:12}' isalnum(): {is_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isalpha() - Validate name fields\n",
    "names = [\"John\", \"Jane123\", \"O'Brien\", \"María\", \"Bob Smith\"]\n",
    "\n",
    "print(\"Validating names (letters only):\")\n",
    "print(\"-\" * 40)\n",
    "for name in names:\n",
    "    is_valid = name.isalpha()\n",
    "    print(f\"'{name:12}' isalpha(): {is_valid}\")\n",
    "\n",
    "print(\"\\nNote: spaces, apostrophes, etc. make isalpha() return False!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 `isspace()` - Check for Whitespace\n",
    "\n",
    "**DE Use Case:** Detecting empty or whitespace-only fields (data quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting empty/whitespace fields in data\n",
    "records = [\n",
    "    {\"name\": \"John\", \"city\": \"NYC\"},\n",
    "    {\"name\": \"Jane\", \"city\": \"   \"},      # Whitespace only\n",
    "    {\"name\": \"Bob\", \"city\": \"\"},           # Empty\n",
    "    {\"name\": \"   \", \"city\": \"Chicago\"},   # Whitespace name\n",
    "]\n",
    "\n",
    "print(\"Detecting problematic fields:\")\n",
    "print(\"-\" * 50)\n",
    "for i, record in enumerate(records):\n",
    "    name_issue = not record[\"name\"] or record[\"name\"].isspace()\n",
    "    city_issue = not record[\"city\"] or record[\"city\"].isspace()\n",
    "    \n",
    "    issues = []\n",
    "    if name_issue:\n",
    "        issues.append(\"name\")\n",
    "    if city_issue:\n",
    "        issues.append(\"city\")\n",
    "    \n",
    "    status = f\"Issues: {issues}\" if issues else \"OK\"\n",
    "    print(f\"Record {i}: {record} → {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Formatting & Alignment\n",
    "\n",
    "Creating formatted output and fixed-width fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 `zfill()` - Zero-Padding\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.zfill(width)\n",
    "```\n",
    "\n",
    "**DE Use Case:** Creating zero-padded IDs, batch numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zfill() - Create consistent ID formats\n",
    "order_numbers = [\"1\", \"42\", \"123\", \"9999\"]\n",
    "\n",
    "print(\"Creating 8-digit order IDs:\")\n",
    "print(\"-\" * 30)\n",
    "for num in order_numbers:\n",
    "    padded = num.zfill(8)\n",
    "    print(f\"'{num}' → '{padded}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zfill() handles negative numbers correctly\n",
    "numbers = [\"42\", \"-42\", \"7\", \"-7\"]\n",
    "\n",
    "print(\"zfill() with negative numbers:\")\n",
    "print(\"-\" * 30)\n",
    "for num in numbers:\n",
    "    padded = num.zfill(5)\n",
    "    print(f\"'{num}' → '{padded}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 `ljust()`, `rjust()`, `center()` - Text Alignment\n",
    "\n",
    "**Syntax:**\n",
    "```\n",
    "string.ljust(width[, fillchar])   # Left-align\n",
    "string.rjust(width[, fillchar])   # Right-align\n",
    "string.center(width[, fillchar])  # Center\n",
    "```\n",
    "\n",
    "**DE Use Case:** Fixed-width file formats, formatted reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating fixed-width formatted output\n",
    "data = [\n",
    "    (\"John Doe\", 1500.00, \"NYC\"),\n",
    "    (\"Jane Smith\", 2500.50, \"LA\"),\n",
    "    (\"Bob Johnson\", 750.25, \"Chicago\"),\n",
    "]\n",
    "\n",
    "print(\"Fixed-width formatted report:\")\n",
    "print(\"=\" * 45)\n",
    "# Header\n",
    "print(f\"{'Name'.ljust(15)} | {'Amount'.rjust(10)} | {'City'.center(10)}\")\n",
    "print(\"-\" * 45)\n",
    "# Data rows\n",
    "for name, amount, city in data:\n",
    "    print(f\"{name.ljust(15)} | {str(amount).rjust(10)} | {city.center(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Quick Reference: Most Used Methods in Data Engineering\n",
    "\n",
    "| Method | Use Case |\n",
    "|--------|----------|\n",
    "| `strip()` | Clean whitespace from raw data |\n",
    "| `lower()` | Normalize emails, case-insensitive matching |\n",
    "| `split()` | Parse CSV/log data into fields |\n",
    "| `join()` | Build CSV rows, file paths |\n",
    "| `replace()` | Standardize formats, clean data |\n",
    "| `startswith()`/`endswith()` | Filter files, identify record types |\n",
    "| `isdigit()` | Validate numeric strings |\n",
    "| `find()` | Locate substrings for parsing |\n",
    "| `partition()` | Extract key-value pairs |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
